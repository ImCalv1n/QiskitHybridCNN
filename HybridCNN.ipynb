{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UD_8Kn2uvsOc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/cwetzel3/.bashrc: line 1: /home/umrigar/cs220/bin/student.rc: No such file or directory\n",
            "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to create the collection: Prompt dismissed..\u001b[0m\n",
            "Collecting qiskit==0.35.0\n",
            "  Downloading qiskit-0.35.0.tar.gz (13 kB)\n",
            "Collecting qiskit-aer==0.10.3\n",
            "  Downloading qiskit_aer-0.10.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (18.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.0 MB 260 kB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.18.3\n",
            "  Downloading qiskit_ibmq_provider-0.18.3-py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 77.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting qiskit-ignis==0.7.0\n",
            "  Downloading qiskit_ignis-0.7.0-py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 78.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting qiskit-terra==0.20.0\n",
            "  Downloading qiskit_terra-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 72.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/lib/python3/dist-packages (from qiskit-aer==0.10.3->qiskit==0.35.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/lib/python3/dist-packages (from qiskit-aer==0.10.3->qiskit==0.35.0) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/lib/python3/dist-packages (from qiskit-ibmq-provider==0.18.3->qiskit==0.35.0) (2.8.1)\n",
            "Collecting requests-ntlm>=1.1.0\n",
            "  Downloading requests_ntlm-1.2.0-py3-none-any.whl (6.0 kB)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/lib/python3/dist-packages (from qiskit-ibmq-provider==0.18.3->qiskit==0.35.0) (2.25.1)\n",
            "Collecting websocket-client>=1.0.1\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.5 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3/dist-packages (from qiskit-ibmq-provider==0.18.3->qiskit==0.35.0) (1.26.5)\n",
            "Collecting retworkx>=0.8.0\n",
            "  Downloading retworkx-0.12.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/lib/python3/dist-packages (from qiskit-ignis==0.7.0->qiskit==0.35.0) (52.0.0)\n",
            "Collecting ply>=3.10\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.6 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: stevedore>=3.0.0 in /usr/lib/python3/dist-packages (from qiskit-terra==0.20.0->qiskit==0.35.0) (3.2.2)\n",
            "Requirement already satisfied: psutil>=5 in /usr/lib/python3/dist-packages (from qiskit-terra==0.20.0->qiskit==0.35.0) (5.8.0)\n",
            "Collecting python-constraint>=1.4\n",
            "  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n",
            "Collecting tweedledum<2.0,>=1.1\n",
            "  Downloading tweedledum-1.1.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (930 kB)\n",
            "\u001b[K     |████████████████████████████████| 930 kB 62.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting symengine>=0.9\n",
            "  Downloading symengine-0.10.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (37.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.5 MB 74.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting dill>=0.3\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 78.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sympy>=1.3\n",
            "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 69.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=1.3 in /usr/lib/python3/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.3->qiskit==0.35.0) (3.3.2)\n",
            "Collecting pyspnego>=0.1.6\n",
            "  Downloading pyspnego-0.8.0-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 82.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting rustworkx==0.12.1\n",
            "  Downloading rustworkx-0.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 69.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[K     |████████████████████████████████| 536 kB 75.8 MB/s eta 0:00:01\n",
            "\u001b[?25hBuilding wheels for collected packages: qiskit, python-constraint\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for qiskit: filename=qiskit-0.35.0-py3-none-any.whl size=11826 sha256=2dcf8ff73a955ffa7630d8a5d171d0eb3a4d454702b7534f82bc7e0037be8554\n",
            "  Stored in directory: /home/cwetzel3/.cache/pip/wheels/b1/08/a0/07e20051bada9ff196cd88a77cb45451db968857302aa2cf77\n",
            "  Building wheel for python-constraint (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24080 sha256=90191aee45b223b83c18e6039b8404c160e7e69411d5f1dbf4801b4bf1fae39c\n",
            "  Stored in directory: /home/cwetzel3/.cache/pip/wheels/51/36/1f/c2ccb8dc4eba38c5215636d4ae2c480b32069cab0376bcc1a4\n",
            "Successfully built qiskit python-constraint\n",
            "Installing collected packages: rustworkx, mpmath, tweedledum, sympy, symengine, retworkx, python-constraint, pyspnego, ply, dill, websocket-client, requests-ntlm, qiskit-terra, qiskit-ignis, qiskit-ibmq-provider, qiskit-aer, qiskit\n",
            "\u001b[33m  WARNING: The script isympy is installed in '/home/cwetzel3/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script pyspnego-parse is installed in '/home/cwetzel3/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script wsdump is installed in '/home/cwetzel3/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed dill-0.3.6 mpmath-1.3.0 ply-3.11 pyspnego-0.8.0 python-constraint-1.4.0 qiskit-0.35.0 qiskit-aer-0.10.3 qiskit-ibmq-provider-0.18.3 qiskit-ignis-0.7.0 qiskit-terra-0.20.0 requests-ntlm-1.2.0 retworkx-0.12.1 rustworkx-0.12.1 symengine-0.10.0 sympy-1.11.1 tweedledum-1.1.1 websocket-client-1.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit==0.35.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7oHpez4xvYeI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2559cd1be80c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import qiskit\n",
        "from qiskit import transpile, assemble\n",
        "from qiskit.visualization import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "QUBITS_PER_CIRCUIT = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Teu4t-H9v9W2"
      },
      "outputs": [],
      "source": [
        "class QuantumCircuit:\n",
        "    \"\"\" \n",
        "    This class provides a simple interface for interaction \n",
        "    with the quantum circuit \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_qubits, backend, shots):\n",
        "        # --- Circuit definition ---\n",
        "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
        "        \n",
        "        all_qubits = [i for i in range(n_qubits)]\n",
        "        self.theta = qiskit.circuit.Parameter('theta')\n",
        "        \n",
        "        self._circuit.h(all_qubits)\n",
        "        self._circuit.barrier()\n",
        "        self._circuit.ry(self.theta, all_qubits)\n",
        "        \n",
        "        self._circuit.measure_all()\n",
        "        # ---------------------------\n",
        "\n",
        "        self.backend = backend\n",
        "        self.shots = shots\n",
        "    \n",
        "    def run(self, thetas):\n",
        "        t_qc = transpile(self._circuit,\n",
        "                         self.backend)\n",
        "        qobj = assemble(t_qc,\n",
        "                        shots=self.shots,\n",
        "                        parameter_binds = [{self.theta: theta} for theta in thetas])\n",
        "        job = self.backend.run(qobj)\n",
        "        result = job.result().get_counts()\n",
        "        \n",
        "        counts = np.array(list(result.values()))\n",
        "        states = np.array(list(result.keys())).astype(float)\n",
        "        \n",
        "        # Compute probabilities for each state\n",
        "        probabilities = counts / self.shots\n",
        "        # Get state expectation\n",
        "        expectation = np.sum(states * probabilities)\n",
        "        #print(expectation)\n",
        "        \n",
        "        return np.array([expectation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class QuantumCircuit2: #electric boogaloo\n",
        "    \"\"\" \n",
        "    This class provides a simple interface for interaction \n",
        "    with the quantum circuit \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_qubits, backend, shots):\n",
        "        # --- Circuit definition ---\n",
        "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
        "        \n",
        "        all_qubits = [i for i in range(n_qubits)]\n",
        "        self.theta = qiskit.circuit.Parameter('theta')\n",
        "        \n",
        "        self._circuit.h(all_qubits)\n",
        "        self._circuit.barrier()\n",
        "        self._circuit.ry(self.theta, all_qubits)\n",
        "        \n",
        "        self._circuit.measure_all()\n",
        "        # ---------------------------\n",
        "\n",
        "        self.backend = backend\n",
        "        self.shots = shots\n",
        "    \n",
        "    def run(self, thetas):\n",
        "        t_qc = transpile(self._circuit,\n",
        "                         self.backend)\n",
        "        qobj = assemble(t_qc,\n",
        "                        shots=self.shots,\n",
        "                        parameter_binds = [{self.theta: theta} for theta in thetas])\n",
        "        job = self.backend.run(qobj)\n",
        "        result = job.result().get_counts()\n",
        "        \n",
        "        counts = np.array(list(result.values()))\n",
        "        states = np.array(list(result.keys())).astype(float)\n",
        "        \n",
        "        # Compute probabilities for each state\n",
        "        probabilities = counts / self.shots\n",
        "        # Get state expectation\n",
        "        expectation = np.sum(states * probabilities)\n",
        "        #print(expectation)\n",
        "        \n",
        "        return np.array([expectation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOPXpw9FwAiG"
      },
      "outputs": [],
      "source": [
        "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
        "\n",
        "circuit = QuantumCircuit(QUBITS_PER_CIRCUIT, simulator, 100)\n",
        "print('Expected value for rotation pi {}'.format(circuit.run([np.pi])[0]))\n",
        "circuit._circuit.draw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD8r3whTwGCT"
      },
      "outputs": [],
      "source": [
        "class HybridFunction(Function):\n",
        "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def forward(ctx, input, quantum_circuit, quantum_circuit2, shift):\n",
        "        \"\"\" Forward pass computation \"\"\"\n",
        "        ctx.shift = shift\n",
        "        ctx.quantum_circuit = quantum_circuit\n",
        "        ctx.quantum_circuit2 = quantum_circuit2\n",
        "\n",
        "        expectation_z = ctx.quantum_circuit.run([ input[0][0].tolist() ])\n",
        "        expectation_z2 = ctx.quantum_circuit2.run([ input[0][1].tolist() ])\n",
        "        result = torch.tensor([expectation_z, expectation_z2])\n",
        "        ctx.save_for_backward(input, result)\n",
        "\n",
        "        return result\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\" Backward pass computation \"\"\"\n",
        "        input, expectation_z = ctx.saved_tensors\n",
        "        input_list = np.array(input.tolist())\n",
        "\n",
        "        #print(input_list)\n",
        "        \n",
        "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
        "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
        "\n",
        "        length = len(input_list[0])\n",
        "        split = int(length / 2)\n",
        "        \n",
        "        #ive come to the conclusion that thetas only ever has one theta in it\n",
        "        #based on how we are using this code. This code will more than likely\n",
        "        #break if you want to use two thetas. I think that they wrote this\n",
        "        #to in theory let you rin the quantum circuit on more than one input\n",
        "        #but didn't actually test it because it won't work with multiple thetas\n",
        "\n",
        "        gradients = []\n",
        "        for i in range(0, split):\n",
        "            expectation_right = ctx.quantum_circuit.run([ shift_right[0][i].tolist() ])\n",
        "            expectation_left  = ctx.quantum_circuit.run([ shift_left[0][i].tolist() ])\n",
        "            \n",
        "            #gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
        "            gradient = (expectation_right) - (expectation_left)\n",
        "            gradients.append(gradient)\n",
        "          \n",
        "        for i in range(split, length):\n",
        "            expectation_right = ctx.quantum_circuit2.run([ shift_right[0][i].tolist() ])\n",
        "            expectation_left  = ctx.quantum_circuit2.run([ shift_left[0][i].tolist() ])\n",
        "            \n",
        "            #gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
        "            gradient = (expectation_right) - (expectation_left)\n",
        "            gradients.append(gradient)\n",
        "        \n",
        "        gradients = np.array([gradients]).T\n",
        "\n",
        "        ret = torch.tensor(gradients).float() * grad_output.float()\n",
        "\n",
        "        return ret.view(1,2), None, None, None\n",
        "\n",
        "class Hybrid(nn.Module):\n",
        "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
        "    \n",
        "    def __init__(self, backend, shots, shift):\n",
        "        super(Hybrid, self).__init__()\n",
        "        self.quantum_circuit = QuantumCircuit(QUBITS_PER_CIRCUIT, backend, shots)\n",
        "        self.quantum_circuit2 = QuantumCircuit2(QUBITS_PER_CIRCUIT, backend, shots)\n",
        "        self.shift = shift\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return HybridFunction.apply(input, self.quantum_circuit, self.quantum_circuit2, self.shift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0c9vAPXwJFd"
      },
      "outputs": [],
      "source": [
        "# Concentrating on the first 100 samples\n",
        "n_samples = 100\n",
        "\n",
        "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
        "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "# Leaving only labels 0 and 1 \n",
        "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
        "                np.where(X_train.targets == 1)[0][:n_samples])\n",
        "#adding 100 samples from rest\n",
        "idx = np.append(idx, np.where(X_train.targets == 2)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_train.targets == 3)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_train.targets == 4)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_train.targets == 5)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_train.targets == 6)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_train.targets == 7)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_train.targets == 8)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_train.targets == 9)[0][:n_samples])\n",
        "\n",
        "X_train.data = X_train.data[idx]\n",
        "X_train.targets = X_train.targets[idx]\n",
        "\n",
        "print(X_train)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQXL5a6uwL5C"
      },
      "outputs": [],
      "source": [
        "n_samples_show = 6\n",
        "\n",
        "data_iter = iter(train_loader)\n",
        "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
        "\n",
        "while n_samples_show > 0:\n",
        "    images, targets = data_iter.__next__()\n",
        "\n",
        "    axes[n_samples_show - 1].imshow(images[0].numpy().squeeze(), cmap='gray')\n",
        "    axes[n_samples_show - 1].set_xticks([])\n",
        "    axes[n_samples_show - 1].set_yticks([])\n",
        "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets.item()))\n",
        "    \n",
        "    n_samples_show -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVq45z_ewQZ7"
      },
      "outputs": [],
      "source": [
        "n_samples = 15\n",
        "\n",
        "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
        "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
        "                np.where(X_test.targets == 1)[0][:n_samples])\n",
        "\n",
        "idx = np.append(idx, np.where(X_test.targets == 2)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_test.targets == 3)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_test.targets == 4)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_test.targets == 5)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_test.targets == 6)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_test.targets == 7)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_test.targets == 8)[0][:n_samples])\n",
        "idx = np.append(idx, np.where(X_test.targets == 9)[0][:n_samples])\n",
        "\n",
        "X_test.data = X_test.data[idx]\n",
        "X_test.targets = X_test.targets[idx]\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDB1R7ebwUYZ"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(256, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "        self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
        "        #added\n",
        "        self.fc3 = nn.Linear(2, 10)\n",
        "        self.lsm = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(1, -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.hybrid(x)\n",
        "        #hybrid returns a 64-bit float, so we must cast to 32 bit for the last linear layer\n",
        "        x = x.type(torch.float32)\n",
        "        x = torch.reshape(x, (1, 2))\n",
        "        x = self.fc3(x)\n",
        "        #need a logsoftmax layer\n",
        "        x = self.lsm(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVIWJstdwYPL"
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "loss_func = nn.NLLLoss()\n",
        "\n",
        "#20\n",
        "epochs = 20\n",
        "loss_list = []\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    total_loss = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        # Calculating loss\n",
        "        loss = loss_func(output, target)\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Optimize the weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss.append(loss.item())\n",
        "    loss_list.append(sum(total_loss)/len(total_loss))\n",
        "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
        "        100. * (epoch + 1) / epochs, loss_list[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MncO96_zw5on"
      },
      "outputs": [],
      "source": [
        "plt.plot(loss_list)\n",
        "plt.title('Hybrid NN Training Convergence')\n",
        "plt.xlabel('Training Iterations')\n",
        "plt.ylabel('Neg Log Likelihood Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyEL8vLGw-LQ"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    \n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        output = model(data)\n",
        "        \n",
        "        pred = output.argmax(dim=1, keepdim=True) \n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        \n",
        "        loss = loss_func(output, target)\n",
        "        total_loss.append(loss.item())\n",
        "        \n",
        "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
        "        sum(total_loss) / len(total_loss),\n",
        "        correct / len(test_loader) * 100)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUi2ERk-xEG7"
      },
      "outputs": [],
      "source": [
        "n_samples_show = 6\n",
        "count = 0\n",
        "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if count == n_samples_show:\n",
        "            break\n",
        "        output = model(data)\n",
        "        \n",
        "        pred = output.argmax(dim=1, keepdim=True) \n",
        "\n",
        "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
        "\n",
        "        axes[count].set_xticks([])\n",
        "        axes[count].set_yticks([])\n",
        "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
        "        \n",
        "        count += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
